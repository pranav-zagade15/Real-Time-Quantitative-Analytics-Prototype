# Real-Time Quantitative Analytics Prototype  
**Gemscap Global Analyst â€“ Quantitative Developer Evaluation**

[![CI](https://github.com/pranav-zagade15/realtime-quant-/actions/workflows/ci.yml/badge.svg)](https://github.com/pranav-zagade15/realtime-quant-/actions/workflows/ci.yml)

---

## Candidate
**Pranav Zagade**  
B.Tech (2026)  
CGPA: **8.11**  
Role Applied: **Quantitative Developer Intern**

---

## Executive Summary

This repository contains a compact yet complete **real-time quantitative analytics prototype** designed to mirror the workflow of a trading and research team operating in statistical arbitrage and relative-value strategies.

The objective is not production deployment, but to demonstrate:
- sound **system design**
- **statistically correct analytics**
- clean separation of concerns
- and the ability to reason about extensibility and scale

The system ingests live market data, aggregates it into time-series structures, computes core quantitative signals, and exposes them through an interactive research dashboard.

---

## Problem Understanding

Modern trading and research workflows require:
- real-time ingestion of noisy tick data
- deterministic aggregation into analyzable structures
- statistically defensible signals
- rapid visual feedback for decision-making

This prototype addresses those needs end-to-end while remaining deliberately simple, readable, and explainable.

---

## High-Level Architecture

```

Market Data Source (Binance Futures WebSocket)
â†“
Ingestion Layer
(ws_client.py)
â†“
In-Memory Time-Series Buffer
& Resampling Utilities
(storage.py)
â†“
Quantitative Analytics Engine
(analytics.py)
â†“
Interactive Research Dashboard
(app.py)
â†“
Alerts + CSV Export Layer
(alerts.py)

```

An architecture diagram (draw.io source + PNG) is included for clarity.

---

## Technology Stack

- **Language:** Python
- **Data Handling:** Pandas, NumPy
- **Statistics:** statsmodels, SciPy
- **Visualization / UI:** Streamlit
- **Testing:** pytest
- **Market Data:** Binance Futures WebSocket

All components are locally runnable and intentionally lightweight.

---

## Component Overview

### 1. Data Ingestion (`ws_client.py`)
- Streams live trade data from Binance Futures WebSocket
- Normalizes raw exchange messages into a clean internal schema:
```

timestamp | symbol | price | quantity

```
- Designed as a pluggable source abstraction so that alternative feeds
(REST, CSV, other exchanges) can be integrated with minimal change

---

### 2. Storage & Resampling (`storage.py`)
- Stateless, deterministic resampling utilities
- Aggregates tick-level data into OHLCV bars
- Supported intervals: **1s / 1m / 5m**
- Explicitly separated from analytics logic to preserve correctness and testability

---

### 3. Quantitative Analytics (`analytics.py`)
Implements commonly used building blocks for relative-value and mean-reversion research:

- **OLS Hedge Ratio**
- Estimated via `statsmodels`
- Used to construct market-neutral spreads

- **Spread Construction**
- Linear combination of correlated assets using the hedge ratio

- **Rolling Z-Score**
- Normalized deviation signal for mean-reversion detection

- **ADF Stationarity Test**
- Validates whether a constructed spread exhibits stationarity

- **Rolling Correlation**
- Measures evolving co-movement between assets

All analytics are implemented as reusable, testable functions operating on Pandas Series.

---

### 4. Alerts (`alerts.py`)
- Lightweight rule-based alerting
- Simple threshold logic (e.g., |Z-score| > N)
- Framework-agnostic and easily extensible

---

### 5. Dashboard (`app.py`)
- Interactive Streamlit-based research interface
- Orchestrates the full pipeline:
ingestion â†’ aggregation â†’ analytics â†’ visualization
- Features:
- Start / stop ingestion
- Live price and analytics charts
- On-demand ADF testing
- Rule-based signal alerts
- CSV export of processed data

The UI is intentionally minimal and research-oriented rather than consumer-styled.

---

## Offline Demonstration Support

To ensure reproducibility and reviewer accessibility, the project includes a
synthetic tick data generator:

```

tools/gen_synthetic_ticks.py

```

This allows the application to be demonstrated without live market connectivity
by loading generated CSV data into the in-memory buffer.

---

## Testing & Validation

Basic unit tests are included to validate analytical correctness and determinism:

- **Analytics Tests**
  - OLS hedge ratio on known linear relationships
  - Rolling Z-score numerical sanity
  - ADF test behavior on seeded stationary series

- **Storage Tests**
  - Deterministic OHLCV aggregation from synthetic tick data

Tests are located in the `tests/` directory and use fixed random seeds to avoid flakiness.

---

## How to Run

### Install dependencies

We recommend using a virtual environment to keep your system environment clean.

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

Or use the Makefile:

```bash
make install
```

Or run the helper script:

```bash
bash scripts/setup_env.sh
```

Note: This workspace container may be system-managed and not allow direct pip installs; in that case create a local venv as shown above. CI (GitHub Actions) will run tests on every push/PR.

### Run unit tests

```bash
pytest -q
```

### Launch the application

```bash
streamlit run app.py
```

---

## Design Philosophy

* **Correctness before complexity**
* **Clear separation of concerns**
* **Stateless, testable components**
* **Architecture that scales conceptually even if the prototype runs locally**
* **Code that can be explained in an interview**

---

## Future Extensions (Not Implemented)

* Persistent streaming via Redis / Kafka
* Time-series databases (TimescaleDB / InfluxDB)
* Structured logging and metrics
* Backtesting harness for signal validation
* Portfolio-level analytics across multiple instruments

These were intentionally left out to preserve clarity and focus.

---

## AI Usage Disclosure

GitHub Copilot and ChatGPT were used to assist with:

* Code scaffolding
* Debugging and refactoring
* Clarification of statistical concepts
* Documentation structuring

All architectural decisions, integration, and final understanding of the system
were performed by the author.

---

## Disclaimer

This project is a **research and evaluation prototype**.
It is not intended for live trading or production deployment.

---

## âœ… Why this README helps you get selected

This document shows that you:
- Think like a **quant + engineer**
- Understand **why** each component exists
- Respect **statistical rigor**
- Can communicate clearly to senior reviewers
- Are honest and transparent about AI usage

This is **exactly what Gemscap wants**.

---

### Next (strongly recommended)
If you want, I can now:
- ðŸŽ¥ Write your **exact 2-minute demo narration**
- ðŸŽ¤ Give **interview answers (2â€“3 lines, senior style)**
- âœ… Do a **final submission checklist**

Just tell me which one.

---

## Reviewer quick test âœ…

1. Generate demo ticks:

```bash
python tools/gen_synthetic_ticks.py --out demo_ticks.csv --symbols SYM1 SYM2 --n 120
```

2. Run unit tests:

```bash
pytest -q
```

3. Launch the dashboard:

```bash
streamlit run app.py
# then upload demo_ticks.csv via the UI
```

If CI is passing and `pytest -q` passes locally, the submission is ready.